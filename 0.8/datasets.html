


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>torchtext.datasets &mdash; torchtext 0.8.0 documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="_static/css/pytorch_theme.css" type="text/css" />
  <link rel="stylesheet" href="https://fonts.googleapis.com/css/family=Lato" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="torchtext.vocab" href="vocab.html" />
    <link rel="prev" title="torchtext.data.metrics" href="data_metrics.html" /> 

  
  <script src="_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <div class="ecosystem-dropdown">
              <a id="dropdownMenuButton" data-toggle="ecosystem-dropdown">
                Ecosystem
              </a>
              <div class="ecosystem-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/hub"">
                  <span class=dropdown-title>Models (Beta)</span>
                  <p>Discover, publish, and reuse pre-trained models</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/ecosystem">
                  <span class=dropdown-title>Tools & Libraries</span>
                  <p>Explore the ecosystem of tools and libraries</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="active">
            <a href="https://pytorch.org/docs/stable/index.html">Docs</a>
          </li>

          <li>
            <div class="resources-dropdown">
              <a id="resourcesDropdownButton" data-toggle="resources-dropdown">
                Resources
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/resources"">
                  <span class=dropdown-title>Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/features">
                  <span class=dropdown-title>About</span>
                  <p>Learn about PyTorch’s features and capabilities</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>

  </div>
</div>


<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            
              
              
                <div class="version">
                  0.8.0
                </div>
              
            

            


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

            
          </div>

          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Package Reference</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="index.html">torchtext</a></li>
<li class="toctree-l1"><a class="reference internal" href="data.html">torchtext.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="nn_modules.html">torchtext.nn.modules.multiheadattention</a></li>
<li class="toctree-l1"><a class="reference internal" href="data_utils.html">torchtext.data.utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="data_functional.html">torchtext.data.functional</a></li>
<li class="toctree-l1"><a class="reference internal" href="data_metrics.html">torchtext.data.metrics</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">torchtext.datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="vocab.html">torchtext.vocab</a></li>
<li class="toctree-l1"><a class="reference internal" href="utils.html">torchtext.utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples.html">examples</a></li>
</ul>
<p class="caption"><span class="caption-text">PyTorch Libraries</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/docs">PyTorch</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/audio">torchaudio</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/text">torchtext</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/vision">torchvision</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/elastic/">TorchElastic</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/serve">TorchServe</a></li>
<li class="toctree-l1"><a class="reference external" href="http://pytorch.org/xla/">PyTorch on XLA Devices</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
      <li>torchtext.datasets</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="_sources/datasets.rst.txt" rel="nofollow"><img src="_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <div class="section" id="torchtext-datasets">
<h1>torchtext.datasets<a class="headerlink" href="#torchtext-datasets" title="Permalink to this headline">¶</a></h1>
<p>All datasets are subclasses of <a class="reference internal" href="data.html#torchtext.data.Dataset" title="torchtext.data.Dataset"><code class="xref py py-class docutils literal notranslate"><span class="pre">torchtext.data.Dataset</span></code></a>, which
inherits from <a class="reference external" href="https://pytorch.org/docs/0.3.0/data.html#torch.utils.data.Dataset" title="(in PyTorch vmaster (0.3.0.post4 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.data.Dataset</span></code></a> i.e, they have <code class="docutils literal notranslate"><span class="pre">split</span></code> and
<code class="docutils literal notranslate"><span class="pre">iters</span></code> methods implemented.</p>
<p>General use cases are as follows:</p>
<p>Approach 1, <code class="docutils literal notranslate"><span class="pre">splits</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># set up fields</span>
<span class="n">TEXT</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">Field</span><span class="p">(</span><span class="n">lower</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">include_lengths</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">LABEL</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">Field</span><span class="p">(</span><span class="n">sequential</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># make splits for data</span>
<span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">IMDB</span><span class="o">.</span><span class="n">splits</span><span class="p">(</span><span class="n">TEXT</span><span class="p">,</span> <span class="n">LABEL</span><span class="p">)</span>

<span class="c1"># build the vocabulary</span>
<span class="n">TEXT</span><span class="o">.</span><span class="n">build_vocab</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">vectors</span><span class="o">=</span><span class="n">GloVe</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;6B&#39;</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">300</span><span class="p">))</span>
<span class="n">LABEL</span><span class="o">.</span><span class="n">build_vocab</span><span class="p">(</span><span class="n">train</span><span class="p">)</span>

<span class="c1"># make iterator for splits</span>
<span class="n">train_iter</span><span class="p">,</span> <span class="n">test_iter</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">BucketIterator</span><span class="o">.</span><span class="n">splits</span><span class="p">(</span>
    <span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">test</span><span class="p">),</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<p>Approach 2, <code class="docutils literal notranslate"><span class="pre">iters</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># use default configurations</span>
<span class="n">train_iter</span><span class="p">,</span> <span class="n">test_iter</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">IMDB</span><span class="o">.</span><span class="n">iters</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
<p>The following datasets are available:</p>
<div class="contents local topic" id="datasets">
<p class="topic-title">Datasets</p>
<ul class="simple">
<li><p><a class="reference internal" href="#language-modeling" id="id1">Language Modeling</a></p>
<ul>
<li><p><a class="reference internal" href="#wikitext-2" id="id2">WikiText-2</a></p></li>
<li><p><a class="reference internal" href="#wikitext103" id="id3">WikiText103</a></p></li>
<li><p><a class="reference internal" href="#penntreebank" id="id4">PennTreebank</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#sentiment-analysis" id="id5">Sentiment Analysis</a></p>
<ul>
<li><p><a class="reference internal" href="#sst" id="id6">SST</a></p></li>
<li><p><a class="reference internal" href="#imdb" id="id7">IMDb</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#text-classification" id="id8">Text Classification</a></p>
<ul>
<li><p><a class="reference internal" href="#textclassificationdataset" id="id9">TextClassificationDataset</a></p></li>
<li><p><a class="reference internal" href="#ag-news" id="id10">AG_NEWS</a></p></li>
<li><p><a class="reference internal" href="#sogounews" id="id11">SogouNews</a></p></li>
<li><p><a class="reference internal" href="#dbpedia" id="id12">DBpedia</a></p></li>
<li><p><a class="reference internal" href="#yelpreviewpolarity" id="id13">YelpReviewPolarity</a></p></li>
<li><p><a class="reference internal" href="#yelpreviewfull" id="id14">YelpReviewFull</a></p></li>
<li><p><a class="reference internal" href="#yahooanswers" id="id15">YahooAnswers</a></p></li>
<li><p><a class="reference internal" href="#amazonreviewpolarity" id="id16">AmazonReviewPolarity</a></p></li>
<li><p><a class="reference internal" href="#amazonreviewfull" id="id17">AmazonReviewFull</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#question-classification" id="id18">Question Classification</a></p>
<ul>
<li><p><a class="reference internal" href="#trec" id="id19">TREC</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#entailment" id="id20">Entailment</a></p>
<ul>
<li><p><a class="reference internal" href="#snli" id="id21">SNLI</a></p></li>
<li><p><a class="reference internal" href="#multinli" id="id22">MultiNLI</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#machine-translation" id="id23">Machine Translation</a></p>
<ul>
<li><p><a class="reference internal" href="#multi30k" id="id24">Multi30k</a></p></li>
<li><p><a class="reference internal" href="#iwslt" id="id25">IWSLT</a></p></li>
<li><p><a class="reference internal" href="#wmt14" id="id26">WMT14</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#sequence-tagging" id="id27">Sequence Tagging</a></p>
<ul>
<li><p><a class="reference internal" href="#udpos" id="id28">UDPOS</a></p></li>
<li><p><a class="reference internal" href="#conll2000chunking" id="id29">CoNLL2000Chunking</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#question-answering" id="id30">Question Answering</a></p>
<ul>
<li><p><a class="reference internal" href="#babi20" id="id31">BABI20</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#unsupervised-learning" id="id32">Unsupervised Learning</a></p>
<ul>
<li><p><a class="reference internal" href="#enwik9" id="id33">EnWik9</a></p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="language-modeling">
<h2><a class="toc-backref" href="#id1">Language Modeling</a><a class="headerlink" href="#language-modeling" title="Permalink to this headline">¶</a></h2>
<p>Language modeling datasets are subclasses of <code class="docutils literal notranslate"><span class="pre">LanguageModelingDataset</span></code> class.</p>
<dl class="class">
<dt id="torchtext.datasets.LanguageModelingDataset">
<em class="property">class </em><code class="sig-prename descclassname">torchtext.datasets.</code><code class="sig-name descname">LanguageModelingDataset</code><span class="sig-paren">(</span><em class="sig-param">path</em>, <em class="sig-param">text_field</em>, <em class="sig-param">newline_eos=True</em>, <em class="sig-param">encoding='utf-8'</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchtext/datasets/language_modeling.html#LanguageModelingDataset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchtext.datasets.LanguageModelingDataset" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines a dataset for language modeling.</p>
<dl class="method">
<dt id="torchtext.datasets.LanguageModelingDataset.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param">path</em>, <em class="sig-param">text_field</em>, <em class="sig-param">newline_eos=True</em>, <em class="sig-param">encoding='utf-8'</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchtext/datasets/language_modeling.html#LanguageModelingDataset.__init__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchtext.datasets.LanguageModelingDataset.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Create a LanguageModelingDataset given a path and a field.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>path</strong> – Path to the data file.</p></li>
<li><p><strong>text_field</strong> – The field that will be used for text data.</p></li>
<li><p><strong>newline_eos</strong> – Whether to add an &lt;eos&gt; token for every newline in the
data file. Default: True.</p></li>
<li><p><strong>keyword arguments</strong> (<em>Remaining</em>) – Passed to the constructor of
data.Dataset.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<div class="section" id="wikitext-2">
<h3><a class="toc-backref" href="#id2">WikiText-2</a><a class="headerlink" href="#wikitext-2" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torchtext.datasets.WikiText2">
<em class="property">class </em><code class="sig-prename descclassname">torchtext.datasets.</code><code class="sig-name descname">WikiText2</code><span class="sig-paren">(</span><em class="sig-param">path</em>, <em class="sig-param">text_field</em>, <em class="sig-param">newline_eos=True</em>, <em class="sig-param">encoding='utf-8'</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchtext/datasets/language_modeling.html#WikiText2"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchtext.datasets.WikiText2" title="Permalink to this definition">¶</a></dt>
<dd><dl class="method">
<dt id="torchtext.datasets.WikiText2.iters">
<em class="property">classmethod </em><code class="sig-name descname">iters</code><span class="sig-paren">(</span><em class="sig-param">batch_size=32</em>, <em class="sig-param">bptt_len=35</em>, <em class="sig-param">device=0</em>, <em class="sig-param">root='.data'</em>, <em class="sig-param">vectors=None</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchtext/datasets/language_modeling.html#WikiText2.iters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchtext.datasets.WikiText2.iters" title="Permalink to this definition">¶</a></dt>
<dd><p>Create iterator objects for splits of the WikiText-2 dataset.</p>
<p>This is the simplest way to use the dataset, and assumes common
defaults for field, vocabulary, and iterator parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch_size</strong> – Batch size.</p></li>
<li><p><strong>bptt_len</strong> – Length of sequences for backpropagation through time.</p></li>
<li><p><strong>device</strong> – Device to create batches on. Use -1 for CPU and None for
the currently active GPU device.</p></li>
<li><p><strong>root</strong> – The root directory that the dataset’s zip archive will be
expanded into; therefore the directory in whose wikitext-2
subdirectory the data files will be stored.</p></li>
<li><p><strong>wv_type, wv_dim</strong> (<em>wv_dir</em><em>,</em>) – Passed to the Vocab constructor for the
text field. The word vectors are accessible as
train.dataset.fields[‘text’].vocab.vectors.</p></li>
<li><p><strong>keyword arguments</strong> (<em>Remaining</em>) – Passed to the splits method.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="torchtext.datasets.WikiText2.splits">
<em class="property">classmethod </em><code class="sig-name descname">splits</code><span class="sig-paren">(</span><em class="sig-param">text_field</em>, <em class="sig-param">root='.data'</em>, <em class="sig-param">train='wiki.train.tokens'</em>, <em class="sig-param">validation='wiki.valid.tokens'</em>, <em class="sig-param">test='wiki.test.tokens'</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchtext/datasets/language_modeling.html#WikiText2.splits"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchtext.datasets.WikiText2.splits" title="Permalink to this definition">¶</a></dt>
<dd><p>Create dataset objects for splits of the WikiText-2 dataset.</p>
<p>This is the most flexible way to use the dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text_field</strong> – The field that will be used for text data.</p></li>
<li><p><strong>root</strong> – The root directory that the dataset’s zip archive will be
expanded into; therefore the directory in whose wikitext-2
subdirectory the data files will be stored.</p></li>
<li><p><strong>train</strong> – The filename of the train data. Default: ‘wiki.train.tokens’.</p></li>
<li><p><strong>validation</strong> – The filename of the validation data, or None to not
load the validation set. Default: ‘wiki.valid.tokens’.</p></li>
<li><p><strong>test</strong> – The filename of the test data, or None to not load the test
set. Default: ‘wiki.test.tokens’.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="wikitext103">
<h3><a class="toc-backref" href="#id3">WikiText103</a><a class="headerlink" href="#wikitext103" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torchtext.datasets.WikiText103">
<em class="property">class </em><code class="sig-prename descclassname">torchtext.datasets.</code><code class="sig-name descname">WikiText103</code><span class="sig-paren">(</span><em class="sig-param">path</em>, <em class="sig-param">text_field</em>, <em class="sig-param">newline_eos=True</em>, <em class="sig-param">encoding='utf-8'</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchtext/datasets/language_modeling.html#WikiText103"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchtext.datasets.WikiText103" title="Permalink to this definition">¶</a></dt>
<dd><dl class="method">
<dt id="torchtext.datasets.WikiText103.iters">
<em class="property">classmethod </em><code class="sig-name descname">iters</code><span class="sig-paren">(</span><em class="sig-param">batch_size=32</em>, <em class="sig-param">bptt_len=35</em>, <em class="sig-param">device=0</em>, <em class="sig-param">root='.data'</em>, <em class="sig-param">vectors=None</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchtext/datasets/language_modeling.html#WikiText103.iters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchtext.datasets.WikiText103.iters" title="Permalink to this definition">¶</a></dt>
<dd><p>Create iterator objects for splits of the WikiText-103 dataset.</p>
<p>This is the simplest way to use the dataset, and assumes common
defaults for field, vocabulary, and iterator parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch_size</strong> – Batch size.</p></li>
<li><p><strong>bptt_len</strong> – Length of sequences for backpropagation through time.</p></li>
<li><p><strong>device</strong> – Device to create batches on. Use -1 for CPU and None for
the currently active GPU device.</p></li>
<li><p><strong>root</strong> – The root directory that the dataset’s zip archive will be
expanded into; therefore the directory in whose wikitext-2
subdirectory the data files will be stored.</p></li>
<li><p><strong>wv_type, wv_dim</strong> (<em>wv_dir</em><em>,</em>) – Passed to the Vocab constructor for the
text field. The word vectors are accessible as
train.dataset.fields[‘text’].vocab.vectors.</p></li>
<li><p><strong>keyword arguments</strong> (<em>Remaining</em>) – Passed to the splits method.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="torchtext.datasets.WikiText103.splits">
<em class="property">classmethod </em><code class="sig-name descname">splits</code><span class="sig-paren">(</span><em class="sig-param">text_field</em>, <em class="sig-param">root='.data'</em>, <em class="sig-param">train='wiki.train.tokens'</em>, <em class="sig-param">validation='wiki.valid.tokens'</em>, <em class="sig-param">test='wiki.test.tokens'</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchtext/datasets/language_modeling.html#WikiText103.splits"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchtext.datasets.WikiText103.splits" title="Permalink to this definition">¶</a></dt>
<dd><p>Create dataset objects for splits of the WikiText-103 dataset.</p>
<p>This is the most flexible way to use the dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text_field</strong> – The field that will be used for text data.</p></li>
<li><p><strong>root</strong> – The root directory that the dataset’s zip archive will be
expanded into; therefore the directory in whose wikitext-103
subdirectory the data files will be stored.</p></li>
<li><p><strong>train</strong> – The filename of the train data. Default: ‘wiki.train.tokens’.</p></li>
<li><p><strong>validation</strong> – The filename of the validation data, or None to not
load the validation set. Default: ‘wiki.valid.tokens’.</p></li>
<li><p><strong>test</strong> – The filename of the test data, or None to not load the test
set. Default: ‘wiki.test.tokens’.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="penntreebank">
<h3><a class="toc-backref" href="#id4">PennTreebank</a><a class="headerlink" href="#penntreebank" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torchtext.datasets.PennTreebank">
<em class="property">class </em><code class="sig-prename descclassname">torchtext.datasets.</code><code class="sig-name descname">PennTreebank</code><span class="sig-paren">(</span><em class="sig-param">path</em>, <em class="sig-param">text_field</em>, <em class="sig-param">newline_eos=True</em>, <em class="sig-param">encoding='utf-8'</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchtext/datasets/language_modeling.html#PennTreebank"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchtext.datasets.PennTreebank" title="Permalink to this definition">¶</a></dt>
<dd><p>The Penn Treebank dataset.
A relatively small dataset originally created for POS tagging.</p>
<p class="rubric">References</p>
<p>Marcus, Mitchell P., Marcinkiewicz, Mary Ann &amp; Santorini, Beatrice (1993).
Building a Large Annotated Corpus of English: The Penn Treebank</p>
<dl class="method">
<dt id="torchtext.datasets.PennTreebank.iters">
<em class="property">classmethod </em><code class="sig-name descname">iters</code><span class="sig-paren">(</span><em class="sig-param">batch_size=32</em>, <em class="sig-param">bptt_len=35</em>, <em class="sig-param">device=0</em>, <em class="sig-param">root='.data'</em>, <em class="sig-param">vectors=None</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchtext/datasets/language_modeling.html#PennTreebank.iters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchtext.datasets.PennTreebank.iters" title="Permalink to this definition">¶</a></dt>
<dd><p>Create iterator objects for splits of the Penn Treebank dataset.</p>
<p>This is the simplest way to use the dataset, and assumes common
defaults for field, vocabulary, and iterator parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch_size</strong> – Batch size.</p></li>
<li><p><strong>bptt_len</strong> – Length of sequences for backpropagation through time.</p></li>
<li><p><strong>device</strong> – Device to create batches on. Use -1 for CPU and None for
the currently active GPU device.</p></li>
<li><p><strong>root</strong> – The root directory where the data files will be stored.</p></li>
<li><p><strong>wv_type, wv_dim</strong> (<em>wv_dir</em><em>,</em>) – Passed to the Vocab constructor for the
text field. The word vectors are accessible as
train.dataset.fields[‘text’].vocab.vectors.</p></li>
<li><p><strong>keyword arguments</strong> (<em>Remaining</em>) – Passed to the splits method.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="torchtext.datasets.PennTreebank.splits">
<em class="property">classmethod </em><code class="sig-name descname">splits</code><span class="sig-paren">(</span><em class="sig-param">text_field</em>, <em class="sig-param">root='.data'</em>, <em class="sig-param">train='ptb.train.txt'</em>, <em class="sig-param">validation='ptb.valid.txt'</em>, <em class="sig-param">test='ptb.test.txt'</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchtext/datasets/language_modeling.html#PennTreebank.splits"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchtext.datasets.PennTreebank.splits" title="Permalink to this definition">¶</a></dt>
<dd><p>Create dataset objects for splits of the Penn Treebank dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text_field</strong> – The field that will be used for text data.</p></li>
<li><p><strong>root</strong> – The root directory where the data files will be stored.</p></li>
<li><p><strong>train</strong> – The filename of the train data. Default: ‘ptb.train.txt’.</p></li>
<li><p><strong>validation</strong> – The filename of the validation data, or None to not
load the validation set. Default: ‘ptb.valid.txt’.</p></li>
<li><p><strong>test</strong> – The filename of the test data, or None to not load the test
set. Default: ‘ptb.test.txt’.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
</div>
<div class="section" id="sentiment-analysis">
<h2><a class="toc-backref" href="#id5">Sentiment Analysis</a><a class="headerlink" href="#sentiment-analysis" title="Permalink to this headline">¶</a></h2>
<div class="section" id="sst">
<h3><a class="toc-backref" href="#id6">SST</a><a class="headerlink" href="#sst" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torchtext.datasets.SST">
<em class="property">class </em><code class="sig-prename descclassname">torchtext.datasets.</code><code class="sig-name descname">SST</code><span class="sig-paren">(</span><em class="sig-param">path</em>, <em class="sig-param">text_field</em>, <em class="sig-param">label_field</em>, <em class="sig-param">subtrees=False</em>, <em class="sig-param">fine_grained=False</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchtext/datasets/sst.html#SST"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchtext.datasets.SST" title="Permalink to this definition">¶</a></dt>
<dd><dl class="method">
<dt id="torchtext.datasets.SST.iters">
<em class="property">classmethod </em><code class="sig-name descname">iters</code><span class="sig-paren">(</span><em class="sig-param">batch_size=32</em>, <em class="sig-param">device=0</em>, <em class="sig-param">root='.data'</em>, <em class="sig-param">vectors=None</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchtext/datasets/sst.html#SST.iters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchtext.datasets.SST.iters" title="Permalink to this definition">¶</a></dt>
<dd><p>Create iterator objects for splits of the SST dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch_size</strong> – Batch_size</p></li>
<li><p><strong>device</strong> – Device to create batches on. Use - 1 for CPU and None for
the currently active GPU device.</p></li>
<li><p><strong>root</strong> – The root directory that the dataset’s zip archive will be
expanded into; therefore the directory in whose trees
subdirectory the data files will be stored.</p></li>
<li><p><strong>vectors</strong> – one of the available pretrained vectors or a list with each
element one of the available pretrained vectors (see Vocab.load_vectors)</p></li>
<li><p><strong>keyword arguments</strong> (<em>Remaining</em>) – Passed to the splits method.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="torchtext.datasets.SST.splits">
<em class="property">classmethod </em><code class="sig-name descname">splits</code><span class="sig-paren">(</span><em class="sig-param">text_field</em>, <em class="sig-param">label_field</em>, <em class="sig-param">root='.data'</em>, <em class="sig-param">train='train.txt'</em>, <em class="sig-param">validation='dev.txt'</em>, <em class="sig-param">test='test.txt'</em>, <em class="sig-param">train_subtrees=False</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchtext/datasets/sst.html#SST.splits"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchtext.datasets.SST.splits" title="Permalink to this definition">¶</a></dt>
<dd><p>Create dataset objects for splits of the SST dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text_field</strong> – The field that will be used for the sentence.</p></li>
<li><p><strong>label_field</strong> – The field that will be used for label data.</p></li>
<li><p><strong>root</strong> – The root directory that the dataset’s zip archive will be
expanded into; therefore the directory in whose trees
subdirectory the data files will be stored.</p></li>
<li><p><strong>train</strong> – The filename of the train data. Default: ‘train.txt’.</p></li>
<li><p><strong>validation</strong> – The filename of the validation data, or None to not
load the validation set. Default: ‘dev.txt’.</p></li>
<li><p><strong>test</strong> – The filename of the test data, or None to not load the test
set. Default: ‘test.txt’.</p></li>
<li><p><strong>train_subtrees</strong> – Whether to use all subtrees in the training set.
Default: False.</p></li>
<li><p><strong>keyword arguments</strong> (<em>Remaining</em>) – Passed to the splits method of
Dataset.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="imdb">
<h3><a class="toc-backref" href="#id7">IMDb</a><a class="headerlink" href="#imdb" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torchtext.datasets.IMDB">
<em class="property">class </em><code class="sig-prename descclassname">torchtext.datasets.</code><code class="sig-name descname">IMDB</code><span class="sig-paren">(</span><em class="sig-param">path</em>, <em class="sig-param">text_field</em>, <em class="sig-param">label_field</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchtext/datasets/imdb.html#IMDB"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchtext.datasets.IMDB" title="Permalink to this definition">¶</a></dt>
<dd><dl class="method">
<dt id="torchtext.datasets.IMDB.iters">
<em class="property">classmethod </em><code class="sig-name descname">iters</code><span class="sig-paren">(</span><em class="sig-param">batch_size=32</em>, <em class="sig-param">device=0</em>, <em class="sig-param">root='.data'</em>, <em class="sig-param">vectors=None</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchtext/datasets/imdb.html#IMDB.iters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchtext.datasets.IMDB.iters" title="Permalink to this definition">¶</a></dt>
<dd><p>Create iterator objects for splits of the IMDB dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch_size</strong> – Batch_size</p></li>
<li><p><strong>device</strong> – Device to create batches on. Use - 1 for CPU and None for
the currently active GPU device.</p></li>
<li><p><strong>root</strong> – The root directory that contains the imdb dataset subdirectory</p></li>
<li><p><strong>vectors</strong> – one of the available pretrained vectors or a list with each
element one of the available pretrained vectors (see Vocab.load_vectors)</p></li>
<li><p><strong>keyword arguments</strong> (<em>Remaining</em>) – Passed to the splits method.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="torchtext.datasets.IMDB.splits">
<em class="property">classmethod </em><code class="sig-name descname">splits</code><span class="sig-paren">(</span><em class="sig-param">text_field</em>, <em class="sig-param">label_field</em>, <em class="sig-param">root='.data'</em>, <em class="sig-param">train='train'</em>, <em class="sig-param">test='test'</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchtext/datasets/imdb.html#IMDB.splits"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchtext.datasets.IMDB.splits" title="Permalink to this definition">¶</a></dt>
<dd><p>Create dataset objects for splits of the IMDB dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text_field</strong> – The field that will be used for the sentence.</p></li>
<li><p><strong>label_field</strong> – The field that will be used for label data.</p></li>
<li><p><strong>root</strong> – Root dataset storage directory. Default is ‘.data’.</p></li>
<li><p><strong>train</strong> – The directory that contains the training examples</p></li>
<li><p><strong>test</strong> – The directory that contains the test examples</p></li>
<li><p><strong>keyword arguments</strong> (<em>Remaining</em>) – Passed to the splits method of
Dataset.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
</div>
<div class="section" id="text-classification">
<h2><a class="toc-backref" href="#id8">Text Classification</a><a class="headerlink" href="#text-classification" title="Permalink to this headline">¶</a></h2>
<div class="section" id="textclassificationdataset">
<h3><a class="toc-backref" href="#id9">TextClassificationDataset</a><a class="headerlink" href="#textclassificationdataset" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torchtext.datasets.TextClassificationDataset">
<em class="property">class </em><code class="sig-prename descclassname">torchtext.datasets.</code><code class="sig-name descname">TextClassificationDataset</code><span class="sig-paren">(</span><em class="sig-param">vocab</em>, <em class="sig-param">data</em>, <em class="sig-param">labels</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchtext/datasets/text_classification.html#TextClassificationDataset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchtext.datasets.TextClassificationDataset" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines an abstract text classification datasets.
Currently, we only support the following datasets:</p>
<blockquote>
<div><ul class="simple">
<li><p>AG_NEWS</p></li>
<li><p>SogouNews</p></li>
<li><p>DBpedia</p></li>
<li><p>YelpReviewPolarity</p></li>
<li><p>YelpReviewFull</p></li>
<li><p>YahooAnswers</p></li>
<li><p>AmazonReviewPolarity</p></li>
<li><p>AmazonReviewFull</p></li>
</ul>
</div></blockquote>
<dl class="method">
<dt id="torchtext.datasets.TextClassificationDataset.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param">vocab</em>, <em class="sig-param">data</em>, <em class="sig-param">labels</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchtext/datasets/text_classification.html#TextClassificationDataset.__init__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchtext.datasets.TextClassificationDataset.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Initiate text-classification dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>vocab</strong> – Vocabulary object used for dataset.</p></li>
<li><p><strong>data</strong> – a list of label/tokens tuple. tokens are a tensor after
numericalizing the string tokens. label is an integer.
[(label1, tokens1), (label2, tokens2), (label2, tokens3)]</p></li>
<li><p><strong>label</strong> – a set of the labels.
{label1, label2}</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<p>See the examples in examples/text_classification/</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="ag-news">
<h3><a class="toc-backref" href="#id10">AG_NEWS</a><a class="headerlink" href="#ag-news" title="Permalink to this headline">¶</a></h3>
<dl class="function">
<dt id="torchtext.datasets.AG_NEWS">
<code class="sig-prename descclassname">torchtext.datasets.</code><code class="sig-name descname">AG_NEWS</code><span class="sig-paren">(</span><em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchtext/datasets/text_classification.html#AG_NEWS"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchtext.datasets.AG_NEWS" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Defines AG_NEWS datasets.</dt><dd><dl class="simple">
<dt>The labels includes:</dt><dd><ul class="simple">
<li><p>0 : World</p></li>
<li><p>1 : Sports</p></li>
<li><p>2 : Business</p></li>
<li><p>3 : Sci/Tech</p></li>
</ul>
</dd>
</dl>
</dd>
</dl>
<p>Create supervised learning dataset: AG_NEWS</p>
<p>Separately returns the training and test dataset</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>root</strong> – Directory where the datasets are saved. Default: “.data”</p></li>
<li><p><strong>ngrams</strong> – a contiguous sequence of n items from s string text.
Default: 1</p></li>
<li><p><strong>vocab</strong> – Vocabulary used for dataset. If None, it will generate a new
vocabulary based on the train data set.</p></li>
<li><p><strong>include_unk</strong> – include unknown token in the data (Default: False)</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">test_dataset</span> <span class="o">=</span> <span class="n">torchtext</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">AG_NEWS</span><span class="p">(</span><span class="n">ngrams</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="sogounews">
<h3><a class="toc-backref" href="#id11">SogouNews</a><a class="headerlink" href="#sogounews" title="Permalink to this headline">¶</a></h3>
<dl class="function">
<dt id="torchtext.datasets.SogouNews">
<code class="sig-prename descclassname">torchtext.datasets.</code><code class="sig-name descname">SogouNews</code><span class="sig-paren">(</span><em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchtext/datasets/text_classification.html#SogouNews"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchtext.datasets.SogouNews" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Defines SogouNews datasets.</dt><dd><dl class="simple">
<dt>The labels includes:</dt><dd><ul class="simple">
<li><p>0 : Sports</p></li>
<li><p>1 : Finance</p></li>
<li><p>2 : Entertainment</p></li>
<li><p>3 : Automobile</p></li>
<li><p>4 : Technology</p></li>
</ul>
</dd>
</dl>
</dd>
</dl>
<p>Create supervised learning dataset: SogouNews</p>
<p>Separately returns the training and test dataset</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>root</strong> – Directory where the datasets are saved. Default: “.data”</p></li>
<li><p><strong>ngrams</strong> – a contiguous sequence of n items from s string text.
Default: 1</p></li>
<li><p><strong>vocab</strong> – Vocabulary used for dataset. If None, it will generate a new
vocabulary based on the train data set.</p></li>
<li><p><strong>include_unk</strong> – include unknown token in the data (Default: False)</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">test_dataset</span> <span class="o">=</span> <span class="n">torchtext</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">SogouNews</span><span class="p">(</span><span class="n">ngrams</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="dbpedia">
<h3><a class="toc-backref" href="#id12">DBpedia</a><a class="headerlink" href="#dbpedia" title="Permalink to this headline">¶</a></h3>
<dl class="function">
<dt id="torchtext.datasets.DBpedia">
<code class="sig-prename descclassname">torchtext.datasets.</code><code class="sig-name descname">DBpedia</code><span class="sig-paren">(</span><em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchtext/datasets/text_classification.html#DBpedia"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchtext.datasets.DBpedia" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Defines DBpedia datasets.</dt><dd><dl class="simple">
<dt>The labels includes:</dt><dd><ul class="simple">
<li><p>0 : Company</p></li>
<li><p>1 : EducationalInstitution</p></li>
<li><p>2 : Artist</p></li>
<li><p>3 : Athlete</p></li>
<li><p>4 : OfficeHolder</p></li>
<li><p>5 : MeanOfTransportation</p></li>
<li><p>6 : Building</p></li>
<li><p>7 : NaturalPlace</p></li>
<li><p>8 : Village</p></li>
<li><p>9 : Animal</p></li>
<li><p>10 : Plant</p></li>
<li><p>11 : Album</p></li>
<li><p>12 : Film</p></li>
<li><p>13 : WrittenWork</p></li>
</ul>
</dd>
</dl>
</dd>
</dl>
<p>Create supervised learning dataset: DBpedia</p>
<p>Separately returns the training and test dataset</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>root</strong> – Directory where the datasets are saved. Default: “.data”</p></li>
<li><p><strong>ngrams</strong> – a contiguous sequence of n items from s string text.
Default: 1</p></li>
<li><p><strong>vocab</strong> – Vocabulary used for dataset. If None, it will generate a new
vocabulary based on the train data set.</p></li>
<li><p><strong>include_unk</strong> – include unknown token in the data (Default: False)</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">test_dataset</span> <span class="o">=</span> <span class="n">torchtext</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">DBpedia</span><span class="p">(</span><span class="n">ngrams</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="yelpreviewpolarity">
<h3><a class="toc-backref" href="#id13">YelpReviewPolarity</a><a class="headerlink" href="#yelpreviewpolarity" title="Permalink to this headline">¶</a></h3>
<dl class="function">
<dt id="torchtext.datasets.YelpReviewPolarity">
<code class="sig-prename descclassname">torchtext.datasets.</code><code class="sig-name descname">YelpReviewPolarity</code><span class="sig-paren">(</span><em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchtext/datasets/text_classification.html#YelpReviewPolarity"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchtext.datasets.YelpReviewPolarity" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Defines YelpReviewPolarity datasets.</dt><dd><dl class="simple">
<dt>The labels includes:</dt><dd><ul class="simple">
<li><p>0 : Negative polarity.</p></li>
<li><p>1 : Positive polarity.</p></li>
</ul>
</dd>
</dl>
</dd>
</dl>
<p>Create supervised learning dataset: YelpReviewPolarity</p>
<p>Separately returns the training and test dataset</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>root</strong> – Directory where the datasets are saved. Default: “.data”</p></li>
<li><p><strong>ngrams</strong> – a contiguous sequence of n items from s string text.
Default: 1</p></li>
<li><p><strong>vocab</strong> – Vocabulary used for dataset. If None, it will generate a new
vocabulary based on the train data set.</p></li>
<li><p><strong>include_unk</strong> – include unknown token in the data (Default: False)</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">test_dataset</span> <span class="o">=</span> <span class="n">torchtext</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">YelpReviewPolarity</span><span class="p">(</span><span class="n">ngrams</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="yelpreviewfull">
<h3><a class="toc-backref" href="#id14">YelpReviewFull</a><a class="headerlink" href="#yelpreviewfull" title="Permalink to this headline">¶</a></h3>
<dl class="function">
<dt id="torchtext.datasets.YelpReviewFull">
<code class="sig-prename descclassname">torchtext.datasets.</code><code class="sig-name descname">YelpReviewFull</code><span class="sig-paren">(</span><em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchtext/datasets/text_classification.html#YelpReviewFull"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchtext.datasets.YelpReviewFull" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Defines YelpReviewFull datasets.</dt><dd><dl class="simple">
<dt>The labels includes:</dt><dd><p>0 - 4 : rating classes (4 is highly recommended).</p>
</dd>
</dl>
</dd>
</dl>
<p>Create supervised learning dataset: YelpReviewFull</p>
<p>Separately returns the training and test dataset</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>root</strong> – Directory where the datasets are saved. Default: “.data”</p></li>
<li><p><strong>ngrams</strong> – a contiguous sequence of n items from s string text.
Default: 1</p></li>
<li><p><strong>vocab</strong> – Vocabulary used for dataset. If None, it will generate a new
vocabulary based on the train data set.</p></li>
<li><p><strong>include_unk</strong> – include unknown token in the data (Default: False)</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">test_dataset</span> <span class="o">=</span> <span class="n">torchtext</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">YelpReviewFull</span><span class="p">(</span><span class="n">ngrams</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="yahooanswers">
<h3><a class="toc-backref" href="#id15">YahooAnswers</a><a class="headerlink" href="#yahooanswers" title="Permalink to this headline">¶</a></h3>
<dl class="function">
<dt id="torchtext.datasets.YahooAnswers">
<code class="sig-prename descclassname">torchtext.datasets.</code><code class="sig-name descname">YahooAnswers</code><span class="sig-paren">(</span><em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchtext/datasets/text_classification.html#YahooAnswers"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchtext.datasets.YahooAnswers" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Defines YahooAnswers datasets.</dt><dd><dl class="simple">
<dt>The labels includes:</dt><dd><ul class="simple">
<li><p>0 : Society &amp; Culture</p></li>
<li><p>1 : Science &amp; Mathematics</p></li>
<li><p>2 : Health</p></li>
<li><p>3 : Education &amp; Reference</p></li>
<li><p>4 : Computers &amp; Internet</p></li>
<li><p>5 : Sports</p></li>
<li><p>6 : Business &amp; Finance</p></li>
<li><p>7 : Entertainment &amp; Music</p></li>
<li><p>8 : Family &amp; Relationships</p></li>
<li><p>9 : Politics &amp; Government</p></li>
</ul>
</dd>
</dl>
</dd>
</dl>
<p>Create supervised learning dataset: YahooAnswers</p>
<p>Separately returns the training and test dataset</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>root</strong> – Directory where the datasets are saved. Default: “.data”</p></li>
<li><p><strong>ngrams</strong> – a contiguous sequence of n items from s string text.
Default: 1</p></li>
<li><p><strong>vocab</strong> – Vocabulary used for dataset. If None, it will generate a new
vocabulary based on the train data set.</p></li>
<li><p><strong>include_unk</strong> – include unknown token in the data (Default: False)</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">test_dataset</span> <span class="o">=</span> <span class="n">torchtext</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">YahooAnswers</span><span class="p">(</span><span class="n">ngrams</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="amazonreviewpolarity">
<h3><a class="toc-backref" href="#id16">AmazonReviewPolarity</a><a class="headerlink" href="#amazonreviewpolarity" title="Permalink to this headline">¶</a></h3>
<dl class="function">
<dt id="torchtext.datasets.AmazonReviewPolarity">
<code class="sig-prename descclassname">torchtext.datasets.</code><code class="sig-name descname">AmazonReviewPolarity</code><span class="sig-paren">(</span><em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchtext/datasets/text_classification.html#AmazonReviewPolarity"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchtext.datasets.AmazonReviewPolarity" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Defines AmazonReviewPolarity datasets.</dt><dd><dl class="simple">
<dt>The labels includes:</dt><dd><ul class="simple">
<li><p>0 : Negative polarity</p></li>
<li><p>1 : Positive polarity</p></li>
</ul>
</dd>
</dl>
</dd>
</dl>
<p>Create supervised learning dataset: AmazonReviewPolarity</p>
<p>Separately returns the training and test dataset</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>root</strong> – Directory where the datasets are saved. Default: “.data”</p></li>
<li><p><strong>ngrams</strong> – a contiguous sequence of n items from s string text.
Default: 1</p></li>
<li><p><strong>vocab</strong> – Vocabulary used for dataset. If None, it will generate a new
vocabulary based on the train data set.</p></li>
<li><p><strong>include_unk</strong> – include unknown token in the data (Default: False)</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">test_dataset</span> <span class="o">=</span> <span class="n">torchtext</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">AmazonReviewPolarity</span><span class="p">(</span><span class="n">ngrams</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="amazonreviewfull">
<h3><a class="toc-backref" href="#id17">AmazonReviewFull</a><a class="headerlink" href="#amazonreviewfull" title="Permalink to this headline">¶</a></h3>
<dl class="function">
<dt id="torchtext.datasets.AmazonReviewFull">
<code class="sig-prename descclassname">torchtext.datasets.</code><code class="sig-name descname">AmazonReviewFull</code><span class="sig-paren">(</span><em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchtext/datasets/text_classification.html#AmazonReviewFull"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchtext.datasets.AmazonReviewFull" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Defines AmazonReviewFull datasets.</dt><dd><dl class="simple">
<dt>The labels includes:</dt><dd><p>0 - 4 : rating classes (4 is highly recommended)</p>
</dd>
</dl>
</dd>
</dl>
<p>Create supervised learning dataset: AmazonReviewFull</p>
<p>Separately returns the training and test dataset</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>root</strong> – Directory where the dataset are saved. Default: “.data”</p></li>
<li><p><strong>ngrams</strong> – a contiguous sequence of n items from s string text.
Default: 1</p></li>
<li><p><strong>vocab</strong> – Vocabulary used for dataset. If None, it will generate a new
vocabulary based on the train data set.</p></li>
<li><p><strong>include_unk</strong> – include unknown token in the data (Default: False)</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">test_dataset</span> <span class="o">=</span> <span class="n">torchtext</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">AmazonReviewFull</span><span class="p">(</span><span class="n">ngrams</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
</div>
<div class="section" id="question-classification">
<h2><a class="toc-backref" href="#id18">Question Classification</a><a class="headerlink" href="#question-classification" title="Permalink to this headline">¶</a></h2>
<div class="section" id="trec">
<h3><a class="toc-backref" href="#id19">TREC</a><a class="headerlink" href="#trec" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torchtext.datasets.TREC">
<em class="property">class </em><code class="sig-prename descclassname">torchtext.datasets.</code><code class="sig-name descname">TREC</code><span class="sig-paren">(</span><em class="sig-param">path</em>, <em class="sig-param">text_field</em>, <em class="sig-param">label_field</em>, <em class="sig-param">fine_grained=False</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchtext/datasets/trec.html#TREC"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchtext.datasets.TREC" title="Permalink to this definition">¶</a></dt>
<dd><dl class="method">
<dt id="torchtext.datasets.TREC.iters">
<em class="property">classmethod </em><code class="sig-name descname">iters</code><span class="sig-paren">(</span><em class="sig-param">batch_size=32</em>, <em class="sig-param">device=0</em>, <em class="sig-param">root='.data'</em>, <em class="sig-param">vectors=None</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchtext/datasets/trec.html#TREC.iters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchtext.datasets.TREC.iters" title="Permalink to this definition">¶</a></dt>
<dd><p>Create iterator objects for splits of the TREC dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch_size</strong> – Batch_size</p></li>
<li><p><strong>device</strong> – Device to create batches on. Use - 1 for CPU and None for
the currently active GPU device.</p></li>
<li><p><strong>root</strong> – The root directory that contains the trec dataset subdirectory</p></li>
<li><p><strong>vectors</strong> – one of the available pretrained vectors or a list with each
element one of the available pretrained vectors (see Vocab.load_vectors)</p></li>
<li><p><strong>keyword arguments</strong> (<em>Remaining</em>) – Passed to the splits method.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="torchtext.datasets.TREC.splits">
<em class="property">classmethod </em><code class="sig-name descname">splits</code><span class="sig-paren">(</span><em class="sig-param">text_field</em>, <em class="sig-param">label_field</em>, <em class="sig-param">root='.data'</em>, <em class="sig-param">train='train_5500.label'</em>, <em class="sig-param">test='TREC_10.label'</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchtext/datasets/trec.html#TREC.splits"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchtext.datasets.TREC.splits" title="Permalink to this definition">¶</a></dt>
<dd><p>Create dataset objects for splits of the TREC dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text_field</strong> – The field that will be used for the sentence.</p></li>
<li><p><strong>label_field</strong> – The field that will be used for label data.</p></li>
<li><p><strong>root</strong> – Root dataset storage directory. Default is ‘.data’.</p></li>
<li><p><strong>train</strong> – The filename of the train data. Default: ‘train_5500.label’.</p></li>
<li><p><strong>test</strong> – The filename of the test data, or None to not load the test
set. Default: ‘TREC_10.label’.</p></li>
<li><p><strong>keyword arguments</strong> (<em>Remaining</em>) – Passed to the splits method of
Dataset.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
</div>
<div class="section" id="entailment">
<h2><a class="toc-backref" href="#id20">Entailment</a><a class="headerlink" href="#entailment" title="Permalink to this headline">¶</a></h2>
<div class="section" id="snli">
<h3><a class="toc-backref" href="#id21">SNLI</a><a class="headerlink" href="#snli" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torchtext.datasets.SNLI">
<em class="property">class </em><code class="sig-prename descclassname">torchtext.datasets.</code><code class="sig-name descname">SNLI</code><span class="sig-paren">(</span><em class="sig-param">path</em>, <em class="sig-param">format</em>, <em class="sig-param">fields</em>, <em class="sig-param">skip_header=False</em>, <em class="sig-param">csv_reader_params={}</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchtext/datasets/nli.html#SNLI"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchtext.datasets.SNLI" title="Permalink to this definition">¶</a></dt>
<dd><dl class="method">
<dt id="torchtext.datasets.SNLI.iters">
<em class="property">classmethod </em><code class="sig-name descname">iters</code><span class="sig-paren">(</span><em class="sig-param">batch_size=32</em>, <em class="sig-param">device=0</em>, <em class="sig-param">root='.data'</em>, <em class="sig-param">vectors=None</em>, <em class="sig-param">trees=False</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#torchtext.datasets.SNLI.iters" title="Permalink to this definition">¶</a></dt>
<dd><p>Create iterator objects for splits of the SNLI dataset.</p>
<p>This is the simplest way to use the dataset, and assumes common
defaults for field, vocabulary, and iterator parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch_size</strong> – Batch size.</p></li>
<li><p><strong>device</strong> – Device to create batches on. Use -1 for CPU and None for
the currently active GPU device.</p></li>
<li><p><strong>root</strong> – The root directory that the dataset’s zip archive will be
expanded into; therefore the directory in whose wikitext-2
subdirectory the data files will be stored.</p></li>
<li><p><strong>vectors</strong> – one of the available pretrained vectors or a list with each
element one of the available pretrained vectors (see Vocab.load_vectors)</p></li>
<li><p><strong>trees</strong> – Whether to include shift-reduce parser transitions.
Default: False.</p></li>
<li><p><strong>keyword arguments</strong> (<em>Remaining</em>) – Passed to the splits method.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="torchtext.datasets.SNLI.splits">
<em class="property">classmethod </em><code class="sig-name descname">splits</code><span class="sig-paren">(</span><em class="sig-param">text_field</em>, <em class="sig-param">label_field</em>, <em class="sig-param">parse_field=None</em>, <em class="sig-param">root='.data'</em>, <em class="sig-param">train='snli_1.0_train.jsonl'</em>, <em class="sig-param">validation='snli_1.0_dev.jsonl'</em>, <em class="sig-param">test='snli_1.0_test.jsonl'</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchtext/datasets/nli.html#SNLI.splits"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchtext.datasets.SNLI.splits" title="Permalink to this definition">¶</a></dt>
<dd><p>Create dataset objects for splits of the SNLI dataset.</p>
<p>This is the most flexible way to use the dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text_field</strong> – The field that will be used for premise and hypothesis
data.</p></li>
<li><p><strong>label_field</strong> – The field that will be used for label data.</p></li>
<li><p><strong>parse_field</strong> – The field that will be used for shift-reduce parser
transitions, or None to not include them.</p></li>
<li><p><strong>extra_fields</strong> – A dict[json_key: Tuple(field_name, Field)]</p></li>
<li><p><strong>root</strong> – The root directory that the dataset’s zip archive will be
expanded into.</p></li>
<li><p><strong>train</strong> – The filename of the train data. Default: ‘train.jsonl’.</p></li>
<li><p><strong>validation</strong> – The filename of the validation data, or None to not
load the validation set. Default: ‘dev.jsonl’.</p></li>
<li><p><strong>test</strong> – The filename of the test data, or None to not load the test
set. Default: ‘test.jsonl’.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="multinli">
<h3><a class="toc-backref" href="#id22">MultiNLI</a><a class="headerlink" href="#multinli" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torchtext.datasets.MultiNLI">
<em class="property">class </em><code class="sig-prename descclassname">torchtext.datasets.</code><code class="sig-name descname">MultiNLI</code><span class="sig-paren">(</span><em class="sig-param">path</em>, <em class="sig-param">format</em>, <em class="sig-param">fields</em>, <em class="sig-param">skip_header=False</em>, <em class="sig-param">csv_reader_params={}</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchtext/datasets/nli.html#MultiNLI"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchtext.datasets.MultiNLI" title="Permalink to this definition">¶</a></dt>
<dd><dl class="method">
<dt id="torchtext.datasets.MultiNLI.iters">
<em class="property">classmethod </em><code class="sig-name descname">iters</code><span class="sig-paren">(</span><em class="sig-param">batch_size=32</em>, <em class="sig-param">device=0</em>, <em class="sig-param">root='.data'</em>, <em class="sig-param">vectors=None</em>, <em class="sig-param">trees=False</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#torchtext.datasets.MultiNLI.iters" title="Permalink to this definition">¶</a></dt>
<dd><p>Create iterator objects for splits of the SNLI dataset.</p>
<p>This is the simplest way to use the dataset, and assumes common
defaults for field, vocabulary, and iterator parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch_size</strong> – Batch size.</p></li>
<li><p><strong>device</strong> – Device to create batches on. Use -1 for CPU and None for
the currently active GPU device.</p></li>
<li><p><strong>root</strong> – The root directory that the dataset’s zip archive will be
expanded into; therefore the directory in whose wikitext-2
subdirectory the data files will be stored.</p></li>
<li><p><strong>vectors</strong> – one of the available pretrained vectors or a list with each
element one of the available pretrained vectors (see Vocab.load_vectors)</p></li>
<li><p><strong>trees</strong> – Whether to include shift-reduce parser transitions.
Default: False.</p></li>
<li><p><strong>keyword arguments</strong> (<em>Remaining</em>) – Passed to the splits method.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="torchtext.datasets.MultiNLI.splits">
<em class="property">classmethod </em><code class="sig-name descname">splits</code><span class="sig-paren">(</span><em class="sig-param">text_field</em>, <em class="sig-param">label_field</em>, <em class="sig-param">parse_field=None</em>, <em class="sig-param">genre_field=None</em>, <em class="sig-param">root='.data'</em>, <em class="sig-param">train='multinli_1.0_train.jsonl'</em>, <em class="sig-param">validation='multinli_1.0_dev_matched.jsonl'</em>, <em class="sig-param">test='multinli_1.0_dev_mismatched.jsonl'</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchtext/datasets/nli.html#MultiNLI.splits"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchtext.datasets.MultiNLI.splits" title="Permalink to this definition">¶</a></dt>
<dd><p>Create dataset objects for splits of the SNLI dataset.</p>
<p>This is the most flexible way to use the dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text_field</strong> – The field that will be used for premise and hypothesis
data.</p></li>
<li><p><strong>label_field</strong> – The field that will be used for label data.</p></li>
<li><p><strong>parse_field</strong> – The field that will be used for shift-reduce parser
transitions, or None to not include them.</p></li>
<li><p><strong>extra_fields</strong> – A dict[json_key: Tuple(field_name, Field)]</p></li>
<li><p><strong>root</strong> – The root directory that the dataset’s zip archive will be
expanded into.</p></li>
<li><p><strong>train</strong> – The filename of the train data. Default: ‘train.jsonl’.</p></li>
<li><p><strong>validation</strong> – The filename of the validation data, or None to not
load the validation set. Default: ‘dev.jsonl’.</p></li>
<li><p><strong>test</strong> – The filename of the test data, or None to not load the test
set. Default: ‘test.jsonl’.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
</div>
<div class="section" id="machine-translation">
<h2><a class="toc-backref" href="#id23">Machine Translation</a><a class="headerlink" href="#machine-translation" title="Permalink to this headline">¶</a></h2>
<p>Machine translation datasets are subclasses of <code class="docutils literal notranslate"><span class="pre">TranslationDataset</span></code> class.</p>
<dl class="class">
<dt id="torchtext.datasets.TranslationDataset">
<em class="property">class </em><code class="sig-prename descclassname">torchtext.datasets.</code><code class="sig-name descname">TranslationDataset</code><span class="sig-paren">(</span><em class="sig-param">path</em>, <em class="sig-param">exts</em>, <em class="sig-param">fields</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchtext/datasets/translation.html#TranslationDataset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchtext.datasets.TranslationDataset" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines a dataset for machine translation.</p>
<dl class="method">
<dt id="torchtext.datasets.TranslationDataset.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param">path</em>, <em class="sig-param">exts</em>, <em class="sig-param">fields</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchtext/datasets/translation.html#TranslationDataset.__init__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchtext.datasets.TranslationDataset.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Create a TranslationDataset given paths and fields.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>path</strong> – Common prefix of paths to the data files for both languages.</p></li>
<li><p><strong>exts</strong> – A tuple containing the extension to path for each language.</p></li>
<li><p><strong>fields</strong> – A tuple containing the fields that will be used for data
in each language.</p></li>
<li><p><strong>keyword arguments</strong> (<em>Remaining</em>) – Passed to the constructor of
data.Dataset.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<div class="section" id="multi30k">
<h3><a class="toc-backref" href="#id24">Multi30k</a><a class="headerlink" href="#multi30k" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torchtext.datasets.Multi30k">
<em class="property">class </em><code class="sig-prename descclassname">torchtext.datasets.</code><code class="sig-name descname">Multi30k</code><span class="sig-paren">(</span><em class="sig-param">path</em>, <em class="sig-param">exts</em>, <em class="sig-param">fields</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchtext/datasets/translation.html#Multi30k"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchtext.datasets.Multi30k" title="Permalink to this definition">¶</a></dt>
<dd><p>The small-dataset WMT 2016 multimodal task, also known as Flickr30k</p>
<dl class="method">
<dt id="torchtext.datasets.Multi30k.splits">
<em class="property">classmethod </em><code class="sig-name descname">splits</code><span class="sig-paren">(</span><em class="sig-param">exts</em>, <em class="sig-param">fields</em>, <em class="sig-param">root='.data'</em>, <em class="sig-param">train='train'</em>, <em class="sig-param">validation='val'</em>, <em class="sig-param">test='test2016'</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchtext/datasets/translation.html#Multi30k.splits"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchtext.datasets.Multi30k.splits" title="Permalink to this definition">¶</a></dt>
<dd><p>Create dataset objects for splits of the Multi30k dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>exts</strong> – A tuple containing the extension to path for each language.</p></li>
<li><p><strong>fields</strong> – A tuple containing the fields that will be used for data
in each language.</p></li>
<li><p><strong>root</strong> – Root dataset storage directory. Default is ‘.data’.</p></li>
<li><p><strong>train</strong> – The prefix of the train data. Default: ‘train’.</p></li>
<li><p><strong>validation</strong> – The prefix of the validation data. Default: ‘val’.</p></li>
<li><p><strong>test</strong> – The prefix of the test data. Default: ‘test’.</p></li>
<li><p><strong>keyword arguments</strong> (<em>Remaining</em>) – Passed to the splits method of
Dataset.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="iwslt">
<h3><a class="toc-backref" href="#id25">IWSLT</a><a class="headerlink" href="#iwslt" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torchtext.datasets.IWSLT">
<em class="property">class </em><code class="sig-prename descclassname">torchtext.datasets.</code><code class="sig-name descname">IWSLT</code><span class="sig-paren">(</span><em class="sig-param">path</em>, <em class="sig-param">exts</em>, <em class="sig-param">fields</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchtext/datasets/translation.html#IWSLT"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchtext.datasets.IWSLT" title="Permalink to this definition">¶</a></dt>
<dd><p>The IWSLT 2016 TED talk translation task</p>
<dl class="method">
<dt id="torchtext.datasets.IWSLT.splits">
<em class="property">classmethod </em><code class="sig-name descname">splits</code><span class="sig-paren">(</span><em class="sig-param">exts</em>, <em class="sig-param">fields</em>, <em class="sig-param">root='.data'</em>, <em class="sig-param">train='train'</em>, <em class="sig-param">validation='IWSLT16.TED.tst2013'</em>, <em class="sig-param">test='IWSLT16.TED.tst2014'</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchtext/datasets/translation.html#IWSLT.splits"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchtext.datasets.IWSLT.splits" title="Permalink to this definition">¶</a></dt>
<dd><p>Create dataset objects for splits of the IWSLT dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>exts</strong> – A tuple containing the extension to path for each language.</p></li>
<li><p><strong>fields</strong> – A tuple containing the fields that will be used for data
in each language.</p></li>
<li><p><strong>root</strong> – Root dataset storage directory. Default is ‘.data’.</p></li>
<li><p><strong>train</strong> – The prefix of the train data. Default: ‘train’.</p></li>
<li><p><strong>validation</strong> – The prefix of the validation data. Default: ‘val’.</p></li>
<li><p><strong>test</strong> – The prefix of the test data. Default: ‘test’.</p></li>
<li><p><strong>keyword arguments</strong> (<em>Remaining</em>) – Passed to the splits method of
Dataset.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="wmt14">
<h3><a class="toc-backref" href="#id26">WMT14</a><a class="headerlink" href="#wmt14" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torchtext.datasets.WMT14">
<em class="property">class </em><code class="sig-prename descclassname">torchtext.datasets.</code><code class="sig-name descname">WMT14</code><span class="sig-paren">(</span><em class="sig-param">path</em>, <em class="sig-param">exts</em>, <em class="sig-param">fields</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchtext/datasets/translation.html#WMT14"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchtext.datasets.WMT14" title="Permalink to this definition">¶</a></dt>
<dd><p>The WMT 2014 English-German dataset, as preprocessed by Google Brain.</p>
<p>Though this download contains test sets from 2015 and 2016, the train set
differs slightly from WMT 2015 and 2016 and significantly from WMT 2017.</p>
<dl class="method">
<dt id="torchtext.datasets.WMT14.splits">
<em class="property">classmethod </em><code class="sig-name descname">splits</code><span class="sig-paren">(</span><em class="sig-param">exts</em>, <em class="sig-param">fields</em>, <em class="sig-param">root='.data'</em>, <em class="sig-param">train='train.tok.clean.bpe.32000'</em>, <em class="sig-param">validation='newstest2013.tok.bpe.32000'</em>, <em class="sig-param">test='newstest2014.tok.bpe.32000'</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchtext/datasets/translation.html#WMT14.splits"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchtext.datasets.WMT14.splits" title="Permalink to this definition">¶</a></dt>
<dd><p>Create dataset objects for splits of the WMT 2014 dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>exts</strong> – A tuple containing the extensions for each language. Must be
either (‘.en’, ‘.de’) or the reverse.</p></li>
<li><p><strong>fields</strong> – A tuple containing the fields that will be used for data
in each language.</p></li>
<li><p><strong>root</strong> – Root dataset storage directory. Default is ‘.data’.</p></li>
<li><p><strong>train</strong> – The prefix of the train data. Default:
‘train.tok.clean.bpe.32000’.</p></li>
<li><p><strong>validation</strong> – The prefix of the validation data. Default:
‘newstest2013.tok.bpe.32000’.</p></li>
<li><p><strong>test</strong> – The prefix of the test data. Default:
‘newstest2014.tok.bpe.32000’.</p></li>
<li><p><strong>keyword arguments</strong> (<em>Remaining</em>) – Passed to the splits method of
Dataset.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
</div>
<div class="section" id="sequence-tagging">
<h2><a class="toc-backref" href="#id27">Sequence Tagging</a><a class="headerlink" href="#sequence-tagging" title="Permalink to this headline">¶</a></h2>
<p>Sequence tagging datasets are subclasses of <code class="docutils literal notranslate"><span class="pre">SequenceTaggingDataset</span></code> class.</p>
<dl class="class">
<dt id="torchtext.datasets.SequenceTaggingDataset">
<em class="property">class </em><code class="sig-prename descclassname">torchtext.datasets.</code><code class="sig-name descname">SequenceTaggingDataset</code><span class="sig-paren">(</span><em class="sig-param">path</em>, <em class="sig-param">fields</em>, <em class="sig-param">encoding='utf-8'</em>, <em class="sig-param">separator='t'</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchtext/datasets/sequence_tagging.html#SequenceTaggingDataset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchtext.datasets.SequenceTaggingDataset" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines a dataset for sequence tagging. Examples in this dataset
contain paired lists – paired list of words and tags.</p>
<p>For example, in the case of part-of-speech tagging, an example is of the
form
[I, love, PyTorch, .] paired with [PRON, VERB, PROPN, PUNCT]</p>
<p>See torchtext/test/sequence_tagging.py on how to use this class.</p>
<dl class="method">
<dt id="torchtext.datasets.SequenceTaggingDataset.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param">path</em>, <em class="sig-param">fields</em>, <em class="sig-param">encoding='utf-8'</em>, <em class="sig-param">separator='\t'</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchtext/datasets/sequence_tagging.html#SequenceTaggingDataset.__init__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchtext.datasets.SequenceTaggingDataset.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Create a dataset from a list of Examples and Fields.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>examples</strong> – List of Examples.</p></li>
<li><p><strong>fields</strong> (<em>List</em><em>(</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><em>tuple</em></a><em>(</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a><em>, </em><a class="reference internal" href="data.html#torchtext.data.Field" title="torchtext.data.Field"><em>Field</em></a><em>)</em><em>)</em>) – The Fields to use in this tuple. The
string is a field name, and the Field is the associated field.</p></li>
<li><p><strong>filter_pred</strong> (<em>callable</em><em> or </em><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.9)"><em>None</em></a>) – Use only examples for which
filter_pred(example) is True, or use all examples if None.
Default is None.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<div class="section" id="udpos">
<h3><a class="toc-backref" href="#id28">UDPOS</a><a class="headerlink" href="#udpos" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torchtext.datasets.UDPOS">
<em class="property">class </em><code class="sig-prename descclassname">torchtext.datasets.</code><code class="sig-name descname">UDPOS</code><span class="sig-paren">(</span><em class="sig-param">path</em>, <em class="sig-param">fields</em>, <em class="sig-param">encoding='utf-8'</em>, <em class="sig-param">separator='t'</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchtext/datasets/sequence_tagging.html#UDPOS"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchtext.datasets.UDPOS" title="Permalink to this definition">¶</a></dt>
<dd><dl class="method">
<dt id="torchtext.datasets.UDPOS.splits">
<em class="property">classmethod </em><code class="sig-name descname">splits</code><span class="sig-paren">(</span><em class="sig-param">fields</em>, <em class="sig-param">root='.data'</em>, <em class="sig-param">train='en-ud-tag.v2.train.txt'</em>, <em class="sig-param">validation='en-ud-tag.v2.dev.txt'</em>, <em class="sig-param">test='en-ud-tag.v2.test.txt'</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchtext/datasets/sequence_tagging.html#UDPOS.splits"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchtext.datasets.UDPOS.splits" title="Permalink to this definition">¶</a></dt>
<dd><p>Downloads and loads the Universal Dependencies Version 2 POS Tagged
data.</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="conll2000chunking">
<h3><a class="toc-backref" href="#id29">CoNLL2000Chunking</a><a class="headerlink" href="#conll2000chunking" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torchtext.datasets.CoNLL2000Chunking">
<em class="property">class </em><code class="sig-prename descclassname">torchtext.datasets.</code><code class="sig-name descname">CoNLL2000Chunking</code><span class="sig-paren">(</span><em class="sig-param">path</em>, <em class="sig-param">fields</em>, <em class="sig-param">encoding='utf-8'</em>, <em class="sig-param">separator='t'</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchtext/datasets/sequence_tagging.html#CoNLL2000Chunking"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchtext.datasets.CoNLL2000Chunking" title="Permalink to this definition">¶</a></dt>
<dd><dl class="method">
<dt id="torchtext.datasets.CoNLL2000Chunking.splits">
<em class="property">classmethod </em><code class="sig-name descname">splits</code><span class="sig-paren">(</span><em class="sig-param">fields</em>, <em class="sig-param">root='.data'</em>, <em class="sig-param">train='train.txt'</em>, <em class="sig-param">test='test.txt'</em>, <em class="sig-param">validation_frac=0.1</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchtext/datasets/sequence_tagging.html#CoNLL2000Chunking.splits"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchtext.datasets.CoNLL2000Chunking.splits" title="Permalink to this definition">¶</a></dt>
<dd><p>Downloads and loads the CoNLL 2000 Chunking dataset.
NOTE: There is only a train and test dataset so we use 10% of the train set as validation</p>
</dd></dl>

</dd></dl>

</div>
</div>
<div class="section" id="question-answering">
<h2><a class="toc-backref" href="#id30">Question Answering</a><a class="headerlink" href="#question-answering" title="Permalink to this headline">¶</a></h2>
<div class="section" id="babi20">
<h3><a class="toc-backref" href="#id31">BABI20</a><a class="headerlink" href="#babi20" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torchtext.datasets.BABI20">
<em class="property">class </em><code class="sig-prename descclassname">torchtext.datasets.</code><code class="sig-name descname">BABI20</code><span class="sig-paren">(</span><em class="sig-param">path</em>, <em class="sig-param">text_field</em>, <em class="sig-param">only_supporting=False</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchtext/datasets/babi.html#BABI20"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchtext.datasets.BABI20" title="Permalink to this definition">¶</a></dt>
<dd><dl class="method">
<dt id="torchtext.datasets.BABI20.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param">path</em>, <em class="sig-param">text_field</em>, <em class="sig-param">only_supporting=False</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchtext/datasets/babi.html#BABI20.__init__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchtext.datasets.BABI20.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Create a dataset from a list of Examples and Fields.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>examples</strong> – List of Examples.</p></li>
<li><p><strong>fields</strong> (<em>List</em><em>(</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><em>tuple</em></a><em>(</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a><em>, </em><a class="reference internal" href="data.html#torchtext.data.Field" title="torchtext.data.Field"><em>Field</em></a><em>)</em><em>)</em>) – The Fields to use in this tuple. The
string is a field name, and the Field is the associated field.</p></li>
<li><p><strong>filter_pred</strong> (<em>callable</em><em> or </em><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.9)"><em>None</em></a>) – Use only examples for which
filter_pred(example) is True, or use all examples if None.
Default is None.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="torchtext.datasets.BABI20.splits">
<em class="property">classmethod </em><code class="sig-name descname">splits</code><span class="sig-paren">(</span><em class="sig-param">text_field</em>, <em class="sig-param">path=None</em>, <em class="sig-param">root='.data'</em>, <em class="sig-param">task=1</em>, <em class="sig-param">joint=False</em>, <em class="sig-param">tenK=False</em>, <em class="sig-param">only_supporting=False</em>, <em class="sig-param">train=None</em>, <em class="sig-param">validation=None</em>, <em class="sig-param">test=None</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchtext/datasets/babi.html#BABI20.splits"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchtext.datasets.BABI20.splits" title="Permalink to this definition">¶</a></dt>
<dd><p>Create Dataset objects for multiple splits of a dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>path</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – Common prefix of the splits’ file paths, or None to use
the result of cls.download(root).</p></li>
<li><p><strong>root</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – Root dataset storage directory. Default is ‘.data’.</p></li>
<li><p><strong>train</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – Suffix to add to path for the train set, or None for no
train set. Default is None.</p></li>
<li><p><strong>validation</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – Suffix to add to path for the validation set, or None
for no validation set. Default is None.</p></li>
<li><p><strong>test</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – Suffix to add to path for the test set, or None for no test
set. Default is None.</p></li>
<li><p><strong>keyword arguments</strong> (<em>Remaining</em>) – Passed to the constructor of the
Dataset (sub)class being used.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Datasets for train, validation, and
test splits in that order, if provided.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tuple[<a class="reference internal" href="data.html#torchtext.data.Dataset" title="torchtext.data.Dataset">Dataset</a>]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
</div>
<div class="section" id="unsupervised-learning">
<h2><a class="toc-backref" href="#id32">Unsupervised Learning</a><a class="headerlink" href="#unsupervised-learning" title="Permalink to this headline">¶</a></h2>
<div class="section" id="enwik9">
<h3><a class="toc-backref" href="#id33">EnWik9</a><a class="headerlink" href="#enwik9" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torchtext.datasets.EnWik9">
<em class="property">class </em><code class="sig-prename descclassname">torchtext.datasets.</code><code class="sig-name descname">EnWik9</code><span class="sig-paren">(</span><em class="sig-param">begin_line=0</em>, <em class="sig-param">num_lines=6348957</em>, <em class="sig-param">root='.data'</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchtext/datasets/unsupervised_learning.html#EnWik9"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchtext.datasets.EnWik9" title="Permalink to this definition">¶</a></dt>
<dd><p>Compressed size of first 10^9 bytes of enwiki-20060303-pages-articles.xml.
It’s part of Large Text Compression Benchmark project</p>
<dl class="method">
<dt id="torchtext.datasets.EnWik9.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param">begin_line=0</em>, <em class="sig-param">num_lines=6348957</em>, <em class="sig-param">root='.data'</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchtext/datasets/unsupervised_learning.html#EnWik9.__init__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchtext.datasets.EnWik9.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Initiate EnWik9 dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>begin_line</strong> – the number of beginning line. Default: 0</p></li>
<li><p><strong>num_lines</strong> – the number of lines to be loaded. Default: 6348957</p></li>
<li><p><strong>root</strong> – Directory where the datasets are saved. Default: “.data”</p></li>
<li><p><strong>data</strong> – a list of label/tokens tuple. tokens are a tensor after</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">torchtext.datasets</span> <span class="kn">import</span> <span class="n">EnWik9</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">enwik9</span> <span class="o">=</span> <span class="n">EnWik9</span><span class="p">(</span><span class="n">num_lines</span><span class="o">=</span><span class="mi">20000</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">vocab</span> <span class="o">=</span> <span class="n">enwik9</span><span class="o">.</span><span class="n">get_vocab</span><span class="p">()</span>
</pre></div>
</div>
</dd></dl>

</dd></dl>

</div>
</div>
</div>


             </article>
             
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="vocab.html" class="btn btn-neutral float-right" title="torchtext.vocab" accesskey="n" rel="next">Next <img src="_static/images/chevron-right-orange.svg" class="next-page"></a>
      
      
        <a href="data_metrics.html" class="btn btn-neutral" title="torchtext.data.metrics" accesskey="p" rel="prev"><img src="_static/images/chevron-right-orange.svg" class="previous-page"> Previous</a>
      
    </div>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2017, Torch Contributors.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">torchtext.datasets</a><ul>
<li><a class="reference internal" href="#language-modeling">Language Modeling</a><ul>
<li><a class="reference internal" href="#wikitext-2">WikiText-2</a></li>
<li><a class="reference internal" href="#wikitext103">WikiText103</a></li>
<li><a class="reference internal" href="#penntreebank">PennTreebank</a></li>
</ul>
</li>
<li><a class="reference internal" href="#sentiment-analysis">Sentiment Analysis</a><ul>
<li><a class="reference internal" href="#sst">SST</a></li>
<li><a class="reference internal" href="#imdb">IMDb</a></li>
</ul>
</li>
<li><a class="reference internal" href="#text-classification">Text Classification</a><ul>
<li><a class="reference internal" href="#textclassificationdataset">TextClassificationDataset</a></li>
<li><a class="reference internal" href="#ag-news">AG_NEWS</a></li>
<li><a class="reference internal" href="#sogounews">SogouNews</a></li>
<li><a class="reference internal" href="#dbpedia">DBpedia</a></li>
<li><a class="reference internal" href="#yelpreviewpolarity">YelpReviewPolarity</a></li>
<li><a class="reference internal" href="#yelpreviewfull">YelpReviewFull</a></li>
<li><a class="reference internal" href="#yahooanswers">YahooAnswers</a></li>
<li><a class="reference internal" href="#amazonreviewpolarity">AmazonReviewPolarity</a></li>
<li><a class="reference internal" href="#amazonreviewfull">AmazonReviewFull</a></li>
</ul>
</li>
<li><a class="reference internal" href="#question-classification">Question Classification</a><ul>
<li><a class="reference internal" href="#trec">TREC</a></li>
</ul>
</li>
<li><a class="reference internal" href="#entailment">Entailment</a><ul>
<li><a class="reference internal" href="#snli">SNLI</a></li>
<li><a class="reference internal" href="#multinli">MultiNLI</a></li>
</ul>
</li>
<li><a class="reference internal" href="#machine-translation">Machine Translation</a><ul>
<li><a class="reference internal" href="#multi30k">Multi30k</a></li>
<li><a class="reference internal" href="#iwslt">IWSLT</a></li>
<li><a class="reference internal" href="#wmt14">WMT14</a></li>
</ul>
</li>
<li><a class="reference internal" href="#sequence-tagging">Sequence Tagging</a><ul>
<li><a class="reference internal" href="#udpos">UDPOS</a></li>
<li><a class="reference internal" href="#conll2000chunking">CoNLL2000Chunking</a></li>
</ul>
</li>
<li><a class="reference internal" href="#question-answering">Question Answering</a><ul>
<li><a class="reference internal" href="#babi20">BABI20</a></li>
</ul>
</li>
<li><a class="reference internal" href="#unsupervised-learning">Unsupervised Learning</a><ul>
<li><a class="reference internal" href="#enwik9">EnWik9</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
         <script src="_static/jquery.js"></script>
         <script src="_static/underscore.js"></script>
         <script src="_static/doctools.js"></script>
         <script src="_static/language_data.js"></script>
         <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
     

  

  <script type="text/javascript" src="_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col follow-us-col">
          <ul>
            <li class="list-title">Stay Connected</li>
            <li>
              <div id="mc_embed_signup">
                <form
                  action="https://twitter.us14.list-manage.com/subscribe/post?u=75419c71fe0a935e53dfa4a3f&id=91d0dccd39"
                  method="post"
                  id="mc-embedded-subscribe-form"
                  name="mc-embedded-subscribe-form"
                  class="email-subscribe-form validate"
                  target="_blank"
                  novalidate>
                  <div id="mc_embed_signup_scroll" class="email-subscribe-form-fields-wrapper">
                    <div class="mc-field-group">
                      <label for="mce-EMAIL" style="display:none;">Email Address</label>
                      <input type="email" value="" name="EMAIL" class="required email" id="mce-EMAIL" placeholder="Email Address">
                    </div>

                    <div id="mce-responses" class="clear">
                      <div class="response" id="mce-error-response" style="display:none"></div>
                      <div class="response" id="mce-success-response" style="display:none"></div>
                    </div>    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->

                    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_75419c71fe0a935e53dfa4a3f_91d0dccd39" tabindex="-1" value=""></div>

                    <div class="clear">
                      <input type="submit" value="" name="subscribe" id="mc-embedded-subscribe" class="button email-subscribe-button">
                    </div>
                  </div>
                </form>
              </div>

            </li>
          </ul>

          <div class="footer-social-icons">
            <a href="https://www.facebook.com/pytorch" target="_blank" class="facebook"></a>
            <a href="https://twitter.com/pytorch" target="_blank" class="twitter"></a>
            <a href="https://www.youtube.com/pytorch" target="_blank" class="youtube"></a>
          </div>
        </div>
      </div>
    </div>
  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/features">Features</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/hub">PyTorch Hub</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="active">
            <a href="https://pytorch.org/docs/stable/index.html">Docs</a>
          </li>

          <li>
            <a href="https://pytorch.org/resources">Resources</a>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>